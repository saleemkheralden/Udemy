{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "****Importing the libraries****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saleem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:15.562079900Z",
     "start_time": "2023-08-17T14:10:06.034631200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Importing the datasets****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         0                                   1                             2\n0        1                    Toy Story (1995)   Animation|Children's|Comedy\n1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n2        3             Grumpier Old Men (1995)                Comedy|Romance\n3        4            Waiting to Exhale (1995)                  Comedy|Drama\n4        5  Father of the Bride Part II (1995)                        Comedy\n...    ...                                 ...                           ...\n3878  3948             Meet the Parents (2000)                        Comedy\n3879  3949          Requiem for a Dream (2000)                         Drama\n3880  3950                    Tigerland (2000)                         Drama\n3881  3951             Two Family House (2000)                         Drama\n3882  3952               Contender, The (2000)                Drama|Thriller\n\n[3883 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Animation|Children's|Comedy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children's|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3878</th>\n      <td>3948</td>\n      <td>Meet the Parents (2000)</td>\n      <td>Comedy</td>\n    </tr>\n    <tr>\n      <th>3879</th>\n      <td>3949</td>\n      <td>Requiem for a Dream (2000)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>3880</th>\n      <td>3950</td>\n      <td>Tigerland (2000)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>3881</th>\n      <td>3951</td>\n      <td>Two Family House (2000)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>3882</th>\n      <td>3952</td>\n      <td>Contender, The (2000)</td>\n      <td>Drama|Thriller</td>\n    </tr>\n  </tbody>\n</table>\n<p>3883 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None,\n",
    "                     engine='python', encoding='latin-1')\n",
    "movies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:15.606731100Z",
     "start_time": "2023-08-17T14:10:15.565092500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         0  1   2   3      4\n0        1  F   1  10  48067\n1        2  M  56  16  70072\n2        3  M  25  15  55117\n3        4  M  45   7  02460\n4        5  M  25  20  55455\n...    ... ..  ..  ..    ...\n6035  6036  F  25  15  32603\n6036  6037  F  45   1  76006\n6037  6038  F  56   1  14706\n6038  6039  F  45   0  01060\n6039  6040  M  25   6  11106\n\n[6040 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>F</td>\n      <td>1</td>\n      <td>10</td>\n      <td>48067</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>M</td>\n      <td>56</td>\n      <td>16</td>\n      <td>70072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>M</td>\n      <td>25</td>\n      <td>15</td>\n      <td>55117</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>M</td>\n      <td>45</td>\n      <td>7</td>\n      <td>02460</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>M</td>\n      <td>25</td>\n      <td>20</td>\n      <td>55455</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6035</th>\n      <td>6036</td>\n      <td>F</td>\n      <td>25</td>\n      <td>15</td>\n      <td>32603</td>\n    </tr>\n    <tr>\n      <th>6036</th>\n      <td>6037</td>\n      <td>F</td>\n      <td>45</td>\n      <td>1</td>\n      <td>76006</td>\n    </tr>\n    <tr>\n      <th>6037</th>\n      <td>6038</td>\n      <td>F</td>\n      <td>56</td>\n      <td>1</td>\n      <td>14706</td>\n    </tr>\n    <tr>\n      <th>6038</th>\n      <td>6039</td>\n      <td>F</td>\n      <td>45</td>\n      <td>0</td>\n      <td>01060</td>\n    </tr>\n    <tr>\n      <th>6039</th>\n      <td>6040</td>\n      <td>M</td>\n      <td>25</td>\n      <td>6</td>\n      <td>11106</td>\n    </tr>\n  </tbody>\n</table>\n<p>6040 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None,\n",
    "                     engine='python', encoding='latin-1')\n",
    "users\n",
    "# columns are user_id, gender, age, codes correspond to user's job, zip code\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:15.764725Z",
     "start_time": "2023-08-17T14:10:15.605747100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "            0     1  2          3\n0           1  1193  5  978300760\n1           1   661  3  978302109\n2           1   914  3  978301968\n3           1  3408  4  978300275\n4           1  2355  5  978824291\n...       ...   ... ..        ...\n1000204  6040  1091  1  956716541\n1000205  6040  1094  5  956704887\n1000206  6040   562  5  956704746\n1000207  6040  1096  4  956715648\n1000208  6040  1097  4  956715569\n\n[1000209 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1193</td>\n      <td>5</td>\n      <td>978300760</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>661</td>\n      <td>3</td>\n      <td>978302109</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>914</td>\n      <td>3</td>\n      <td>978301968</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3408</td>\n      <td>4</td>\n      <td>978300275</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2355</td>\n      <td>5</td>\n      <td>978824291</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1000204</th>\n      <td>6040</td>\n      <td>1091</td>\n      <td>1</td>\n      <td>956716541</td>\n    </tr>\n    <tr>\n      <th>1000205</th>\n      <td>6040</td>\n      <td>1094</td>\n      <td>5</td>\n      <td>956704887</td>\n    </tr>\n    <tr>\n      <th>1000206</th>\n      <td>6040</td>\n      <td>562</td>\n      <td>5</td>\n      <td>956704746</td>\n    </tr>\n    <tr>\n      <th>1000207</th>\n      <td>6040</td>\n      <td>1096</td>\n      <td>4</td>\n      <td>956715648</td>\n    </tr>\n    <tr>\n      <th>1000208</th>\n      <td>6040</td>\n      <td>1097</td>\n      <td>4</td>\n      <td>956715569</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000209 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None,\n",
    "                     engine='python', encoding='latin-1')\n",
    "ratings\n",
    "\n",
    "# columns are user_id, movie_id, rating, timestamp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:20.957444300Z",
     "start_time": "2023-08-17T14:10:15.652283400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Getting the test and train sets****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[        1,         2,         3, 876893171],\n       [        1,         3,         4, 878542960],\n       [        1,         4,         3, 876893119],\n       ...,\n       [      943,      1188,         3, 888640250],\n       [      943,      1228,         3, 888640275],\n       [      943,      1330,         3, 888692465]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t')\n",
    "training_set = np.array(training_set, dtype='int')\n",
    "training_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.055175Z",
     "start_time": "2023-08-17T14:10:20.964694500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[        1,        10,         3, 875693118],\n       [        1,        12,         5, 878542960],\n       [        1,        14,         5, 874965706],\n       ...,\n       [      459,       934,         3, 879563639],\n       [      460,        10,         3, 882912371],\n       [      462,       682,         5, 886365231]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t')\n",
    "test_set = np.array(test_set, dtype='int')\n",
    "test_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.182283500Z",
     "start_time": "2023-08-17T14:10:21.012139500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Getting total number of users and movies****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "nb_users = len(set(np.concatenate((training_set[:, 0], test_set[:, 0]))))\n",
    "nb_movies = len(set(np.concatenate((training_set[:, 1], test_set[:, 1]))))\n",
    "\n",
    "print(nb_users, nb_movies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.186014800Z",
     "start_time": "2023-08-17T14:10:21.042455400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Convert training and test set to a matrix where the rows are the users and the columns are the movies****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# what was shown in the lectures\n",
    "\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
    "        ratings_arr = np.zeros(nb_movies)\n",
    "        ratings_arr[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings_arr))\n",
    "    return new_data\n",
    "\n",
    "# more elegant way to convert\n",
    "# todo: fix this\n",
    "# but the training set and test set won't be the same shape\n",
    "def pivot(ds: np.ndarray):\n",
    "    return pd.DataFrame(ds).pivot(index=0, columns=1, values=2).to_numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.187014500Z",
     "start_time": "2023-08-17T14:10:21.074593200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.403386100Z",
     "start_time": "2023-08-17T14:10:21.091208700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n",
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "print(len(training_set), len(training_set[0]))\n",
    "print(len(test_set), len(test_set[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.419832200Z",
     "start_time": "2023-08-17T14:10:21.404942300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Convert test and train sets from 2d lists to torch tensors****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.602192100Z",
     "start_time": "2023-08-17T14:10:21.421119700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(training_set)\n",
    "print(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.664228200Z",
     "start_time": "2023-08-17T14:10:21.603193700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Convert the ratings into binary ratings (1 - liked the movie, 0 - didn't like)****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "training_set[training_set == 0] = -1\n",
    "training_set[(0 < training_set) & (training_set <= 2)] = 0\n",
    "training_set[training_set > 2] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.745734300Z",
     "start_time": "2023-08-17T14:10:21.666230500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "test_set[test_set == 0] = -1\n",
    "test_set[(0 < test_set) & (test_set <= 2)] = 0\n",
    "test_set[test_set > 2] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.751445900Z",
     "start_time": "2023-08-17T14:10:21.703201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  1.,  1.,  ..., -1., -1., -1.],\n",
      "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1.,  1., -1.,  ..., -1., -1., -1.]])\n",
      "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "print(training_set)\n",
    "print(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.753142700Z",
     "start_time": "2023-08-17T14:10:21.747093400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Creating the model architecture****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class RBM:\n",
    "\n",
    "    def __init__(self, nv, nh):\n",
    "        self.nv = nv\n",
    "        self.nh = nh\n",
    "        self.w = torch.randn(self.nh, self.nv)\n",
    "        self.a = torch.randn(1, self.nh)\n",
    "        self.b = torch.randn(1, self.nv)\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.w.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.w)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.w += torch.mm(ph0.t(), v0) - torch.mm(phk.t(), vk)\n",
    "        self.b += torch.sum((v0 - vk), 0) # same as v0 - vk but removes the outer dimension\n",
    "        self.a += torch.sum((ph0 - phk), 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.771081800Z",
     "start_time": "2023-08-17T14:10:21.755142200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "\n",
    "rbm = RBM(nv, nh)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:21.828033700Z",
     "start_time": "2023-08-17T14:10:21.766858600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 0.25\n",
      "epoch 2: loss 0.25\n",
      "epoch 3: loss 0.25\n",
      "epoch 4: loss 0.25\n",
      "epoch 5: loss 0.25\n",
      "epoch 6: loss 0.25\n",
      "epoch 7: loss 0.25\n",
      "epoch 8: loss 0.24\n",
      "epoch 9: loss 0.25\n",
      "epoch 10: loss 0.25\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user + batch_size]\n",
    "        v0 = training_set[id_user:id_user + batch_size]\n",
    "        ph0, _ = rbm.sample_h(v0)\n",
    "\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(vk[v0 >= 0] - v0[v0 >= 0]))\n",
    "        s += 1.\n",
    "\n",
    "    print(f'epoch {epoch}: loss {train_loss / s:.2f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:28:47.945482200Z",
     "start_time": "2023-08-17T14:28:40.845159200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.24795620143413544\n"
     ]
    }
   ],
   "source": [
    "# Testing the RBM\n",
    "\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1] # the input which we'll be predicting on\n",
    "    # the training set is the input of the RBM\n",
    "    # we need to input the movies that's already activated to get the ratings of the\n",
    "    # test points that's not yet seen\n",
    "\n",
    "    vt = test_set[id_user:id_user+1] # the target\n",
    "\n",
    "    if len(vt[vt >= 0]) > 0:\n",
    "        _, h = rbm.sample_h(v)\n",
    "        _, v = rbm.sample_v(h)\n",
    "\n",
    "        test_loss += torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0]))\n",
    "        s += 1.\n",
    "print(f\"test loss: {test_loss / s}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:28:48.149352300Z",
     "start_time": "2023-08-17T14:28:47.948482700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:30.893152800Z",
     "start_time": "2023-08-17T14:10:30.850102900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:30.895672Z",
     "start_time": "2023-08-17T14:10:30.866541400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:30.895672Z",
     "start_time": "2023-08-17T14:10:30.871133500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:30.912504700Z",
     "start_time": "2023-08-17T14:10:30.888479900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:30.953128400Z",
     "start_time": "2023-08-17T14:10:30.904691300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:30.956289900Z",
     "start_time": "2023-08-17T14:10:30.923073400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T14:10:30.957288800Z",
     "start_time": "2023-08-17T14:10:30.937720400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
